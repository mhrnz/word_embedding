{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import tensorflow.keras.preprocessing as preprocessing\n",
    "from collections import Counter\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def text_to_word_sequence(text):\n",
    "    words=preprocessing.text.text_to_word_sequence(text, filters='!\"#$%&()*+,-./:;<=>?@[\\]^_`{|}~\\n', lower=True, split=' ')\n",
    "    return words\n",
    "\n",
    "\n",
    "def create_lookup_tables(words):\n",
    "    word_counts = Counter(words)\n",
    "    sorted_vocab = sorted(word_counts, key=word_counts.get, reverse=True)\n",
    "    int_to_vocab = {ii: word for ii, word in enumerate(sorted_vocab)}\n",
    "    vocab_to_int = {word: ii for ii, word in int_to_vocab.items()}\n",
    "\n",
    "    return vocab_to_int, int_to_vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# p_drop(word)=1-sqrt(treshold/freq(word)) , frequent words are more likely to be removed from the dataset\n",
    "def subsampling(int_words):\n",
    "    word_counts=Counter(int_words) # a dictionary from int_word to number of times it appeared in the text\n",
    "    total_count=len(int_words)\n",
    "    p_drops={word:1-np.sqrt(1e-5/(count/total_count)) for word,count in word_counts.items()}\n",
    "    train_words=[word for word in int_words if random.random()<(1-p_drops[word])] # the bigger p_drop the less likely to be chosen\n",
    "    return train_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Since the yield keyword is only used with generators, it makes sense to recall the concept of generators first.\n",
      "\n",
      "The idea of generators is to calculate a series of results one-by-one on demand (on the fly). In the simplest case, a generator can be used as a list, where each element is calculated lazily. Lets compare a list and a generator that do the same thing - return powers of two\n",
      "Iterating over the list and the generator looks completely the same. However, although the generator is iterable, it is not a collection, and thus has no length. Collections (lists, tuples, sets, etc) keep all values in memory and we can access them whenever needed. A generator calculates the values on the fly and forgets them, so it does not have any overview about the own result set.\n",
      "\n",
      "Generators are especially useful for memory-intensive tasks, where there is no need to keep all of the elements of a memory-heavy list accessible at the same time. Calculating a series of values one-by-one can also be useful in situations where the complete result is never needed, yielding intermediate results to the caller until some requirement is satisfied and further processing stops.\n",
      "A good example is a search task, where typically there is no need to wait for all results to be found. Performing a file-system search, a user would be happier to receive results on-the-fly, rather the wait for a search engine to go through every single file and only afterwards return results. Are there any people who really navigate through all Google search results until the last page?\n",
      "\n",
      "Since a search functionality cannot be created using list-comprehensions, we are going to define a generator using a function with the yield statement/keyword. The yield instruction should be put into a place where the generator returns an intermediate result to the caller and sleeps until the next invocation occurs. Let's define a generator that would search for some keyword in a huge text file line-by-line.\n",
      "\n",
      " anarchism originated as a term of abuse first used against early working class radicals including the diggers of the english revolution and the sans culottes of the french revolution whilst the term is still used in a pejorative way to describe any act that used violent means to destroy the organization of society it has also been taken up as a positive label by self defined anarchists the word anarchism is derived from the greek without archons ruler chief king anarchism as a political philosophy is the belief that rulers are unnecessary and should be abolished although there are differing interpretations of what this means anarchism also refers to related social movements that advocate the elimination of authoritarian institutions particularly the state the word anarchy as most anarchists use it does not imply chaos nihilism or anomie but rather a harmonious anti authoritarian society in place of what are regarded as authoritarian political structures and coercive economic institutions anarchists advocate social relations based upon voluntary association of autonomous individuals mutual aid and self governance while anarchism is most easily defined by what it is against anarchists also offer positive visions of what they believe to be a truly free society however ideas about how an anarchist society might work vary considerably especially with respect to economics there is also disagreement about how a free society might be brought about origins and predecessors kropotkin and others argue that before recorded history human society was organized on anarchist principles most anthropologists follow kropotkin and engels in believing that hunter gatherer bands were egalitarian and lacked division of labour accumulated wealth or decreed law and had equal access to resources william godwin anarchists including the the anarchy organisation and rothbard find anarchist attitudes in taoism from ancient china kropotkin found similar ideas in stoic zeno of citium according to kropotkin zeno repudiated the omnipotence of the state its intervention and regimentation and proclaimed the sovereignty of the moral law of the individual the anabaptists of one six th century europe are sometimes considered to be religious forerunners of modern anarchism bertrand russell in his history of western philosophy writes that the anabaptists repudiated all law since they held that the good man will be guided at every moment by the holy spirit from this premise they arrive at communism the diggers or true levellers were an early communistic movement during the time of the english civil war and are considered by some as forerunners of modern anarchism in the modern era the first to use the term to mean something other than chaos was louis armand baron de lahontan in his nouveaux voyages dans l am rique septentrionale one seven zero three where he described the indigenous american society which had no state laws prisons priests or private property as being in anarchy russell means a libertarian and leader in the american indian movement has repeatedly stated that he is an anarchist and so are all his ancestors in one seven nine three in the thick of the french revolution william godwin published an enquiry concerning political justice although godwin did not use the word anarchism many later anarchists have regarded this book as the first major anarchist text and godwin as the founder of philosophical anarchism but at this point no anarchist movement yet existed and the term anarchiste was known mainly as an insult hurled by the bourgeois girondins at more radical elements in the french revolution the first self labelled anarchist pierre joseph proudhon it is commonly held that it wasn t until pierre joseph proudhon published what is property in one eight four zero that the term anarchist was adopted as a self description it is for this reason that some claim proudhon as the founder of modern anarchist theory in what is property proudhon answers with the famous accusation property is theft in this work he opposed the institution of decreed property propri t where owners have complete rights to use and abuse their property as they wish such as exploiting workers for profit in its place proudhon supported what he called possession individuals can have limited rights to use resources capital and goods in accordance with principles of equality and justice proudhon s vision of anarchy which he called mutualism mutuellisme involved an exchange economy where individuals and groups could trade the products of their labor using labor notes which represented the amount of working time involved in production this would ensure that no one would profit from the labor of others workers could freely join together in co operative workshops an interest free bank would be set up to provide everyone with access to the means of production proudhon s ideas were influential within french working class movements and his followers were active in the revolution of one eight four eight in france proudhon s philosophy of property is complex it was developed in a number of works over his lifetime and there are differing interpretations of some of his ideas for more detailed discussion see here max stirner s egoism in his the ego and its own stirner argued that most commonly accepted social institutions including the notion of state property as a right natural rights in general and the very notion of society were mere illusions or ghosts in the mind saying of society that the individuals are its reality he advocated egoism and a form of amoralism in which individuals would unite in associations of egoists only when it was in their self interest to do so for him property simply comes about through might whoever knows how to take to defend the thing to him belongs property and what i have in my power that is my own so long as i assert myself as holder i am the proprietor of the thing stirner never called himself an anarchist he accepted only the label egoist nevertheless his ideas were influential on many individualistically inclined anarchists although interpretations of his thought are diverse american individualist anarchism benjamin tucker in one eight two five josiah warren had participated in a communitarian experiment headed by robert owen called new harmony which failed in a few years amidst much internal conflict warren blamed the community s failure on a lack of individual sovereignty and a lack of private property warren proceeded to organise experimenal anarchist communities which respected what he called the sovereignty of the individual at utopia and modern times in one eight three three warren wrote and published the peaceful revolutionist which some have noted to be the first anarchist periodical ever published benjamin tucker says that warren was the first man to expound and formulate the doctrine now known as anarchism liberty xiv december one nine zero zero one benjamin tucker became interested in anarchism through meeting josiah warren and william b greene he edited and published liberty from august one eight eight one to april one nine zero eight it is widely considered to be the finest individualist anarchist periodical ever issued in the english language tucker s conception of individualist anarchism incorporated the ideas of a variety of theorists greene s ideas on mutual banking warren s ideas on cost as the limit of price a heterodox variety of labour theory of value proudhon s market anarchism max stirner s egoism and herbert spencer s law of equal freedom tucker strongly supported the individual s right to own the product of his or her labour as private property and believed in a market economy for trading this property he argued that in a truly free market system without the state the abundance of competition would eliminate profits and ensure that all workers received the full value of their labor other one nine th century individualists included lysander spooner stephen pearl andrews and victor yarros the first international mikhail bakunin one eight one four one eight seven six in europe harsh reaction followed the revolutions of one eight four eight twenty years later in one eight six four the international workingmen s association sometimes called the first international united some diverse european revolutionary currents including anarchism due to its genuine links to active workers movements the international became signficiant from the start karl marx was a leading figure in the international he was elected to every succeeding general council of the association the first objections to marx came from the mutualists who opposed communism and statism shortly after mikhail bakunin and his followers joined in one eight six eight the first international became polarised into two camps with marx and bakunin as their respective figureheads the clearest difference between the camps was over strategy the anarchists around bakunin favoured in kropotkin s words direct economical struggle against capitalism without interfering in the political parliamentary agitation at that time marx and his followers focused on parliamentary activity bakunin characterised marx s ideas as authoritarian and predicted that if a marxist party gained to power its leaders would end up as bad as the ruling class they had fought against in one eight seven two the conflict climaxed with a final split between the two groups at the hague congress this is often cited as the origin of the conflict between anarchists and marxists from this moment the social democratic and libertarian currents of socialism had distinct organisations including rival internationals anarchist communism peter kropotkin proudhon and bakunin both opposed communism associating it with statism however in the one eight seven zero s many anarchists moved away from bakunin s economic thinking called collectivism and embraced communist concepts communists believed the means of production should be owned collectively and that goods be distributed by need not labor an early anarchist communist was joseph d jacque the first person to describe himself as libertarian unlike proudhon he argued that it is not the product of his or her labor that the worker has a right to but to the satisfaction of his or her needs whatever may be their nature he announced his ideas in his us published journal le libertaire one eight five eight one eight six one peter kropotkin often seen as the most important theorist outlined his economic ideas in the conquest of bread and fields factories and workshops he felt co operation is more beneficial than competition illustrated in nature in mutual aid a factor of evolution one eight nine seven subsequent anarchist communists include emma goldman and alexander berkman many in the anarcho syndicalist movements see below saw anarchist communism as their objective isaac puente s one nine three two comunismo libertario was adopted by the spanish cnt as its manifesto for a post revolutionary society some anarchists disliked merging communism with anarchism several individualist anarchists maintained that abolition of private property was not consistent with liberty for example benjamin tucker whilst professing respect for kropotkin and publishing his work described communist anarchism as pseudo anarchism propaganda of the deed johann most was an outspoken advocate of violence anarchists have often been portrayed as dangerous and violent due mainly to a number of high profile \n",
      "[111, 0, 112, 113, 8, 84, 65, 24, 85, 16, 293, 294, 5, 295, 0, 296, 1, 85, 21, 0, 297, 1, 85, 8, 5, 298, 4, 173, 1, 50, 7, 25, 7, 29, 299, 29, 0, 114, 3, 0, 300, 301, 4, 34, 86, 14, 65, 6, 4, 66, 35, 302, 303, 8, 304, 305, 306, 307, 4, 66, 2, 4, 34, 9, 174, 0, 115, 116, 175, 308, 1, 51, 309, 117, 0, 66, 2, 0, 34, 310, 311, 0, 115, 118, 87, 0, 34, 8, 312, 16, 8, 41, 4, 313, 2, 314, 88, 52, 315, 316, 317, 318, 319, 320, 176, 42, 119, 3, 120, 2, 177, 86, 121, 178, 321, 179, 4, 34, 322, 0, 119, 29, 0, 114, 2, 323, 178, 89, 16, 180, 41, 43, 122, 324, 67, 0, 90, 123, 181, 85, 22, 182, 183, 23, 120, 325, 326, 35, 53, 8, 52, 124, 5, 176, 42, 1, 0, 184, 1, 4, 120, 327, 66, 328, 36, 0, 115, 91, 329, 4, 173, 1, 119, 7, 25, 7, 86, 68, 14, 183, 3, 330, 35, 0, 185, 123, 8, 186, 179, 331, 187, 50, 5, 0, 188, 92, 37, 332, 8, 333, 2, 334, 335, 336, 4, 189, 190, 8, 4, 54, 337, 35, 338, 53, 8, 52, 124, 5, 191, 23, 42, 50, 5, 14, 192, 339, 4, 125, 193, 54, 4, 340, 38, 14, 341, 5, 342, 50, 29, 0, 114, 194, 0, 191, 23, 4, 54, 343, 5, 344, 93, 126, 345, 125, 2, 84, 346, 175, 50, 22, 53, 122, 347, 195, 348, 349, 93, 42, 350, 54, 50, 92, 0, 351, 352, 111, 4, 54, 353, 354, 14, 355, 127, 66, 356, 177, 22, 357, 5, 196, 4, 34, 127, 4, 358, 24, 0, 112, 359, 113, 0, 112, 360, 128, 14, 361, 197, 4, 129, 35, 0, 34, 362, 26, 187, 123, 5, 0, 188, 2, 363, 92, 0, 364, 365, 366, 367, 196, 4, 34, 9, 38, 54, 23, 37, 113, 3, 4, 368, 198, 125, 199, 25, 199, 11, 369, 6, 4, 69, 1, 200, 21, 65, 94, 130, 131, 132, 370, 70, 0, 201, 1, 0, 133, 71, 2, 0, 371, 372, 1, 0, 95, 71, 202, 0, 69, 8, 373, 65, 3, 4, 374, 375, 5, 203, 122, 376, 9, 65, 204, 72, 5, 377, 0, 378, 1, 30, 16, 88, 68, 205, 379, 134, 6, 4, 206, 207, 25, 73, 208, 20, 0, 135, 11, 8, 380, 32, 0, 381, 136, 382, 383, 384, 385, 11, 6, 4, 96, 137, 8, 0, 386, 9, 387, 22, 388, 2, 128, 14, 389, 87, 53, 22, 209, 138, 1, 33, 31, 72, 11, 68, 390, 5, 391, 97, 98, 9, 139, 0, 392, 1, 99, 140, 393, 0, 74, 0, 135, 100, 6, 55, 20, 75, 16, 180, 41, 394, 210, 395, 39, 396, 141, 194, 4, 397, 398, 99, 30, 3, 129, 1, 33, 22, 211, 6, 99, 96, 399, 2, 400, 142, 140, 20, 139, 97, 401, 402, 403, 404, 143, 1, 405, 76, 144, 212, 2, 73, 406, 407, 11, 8, 55, 408, 208, 25, 33, 16, 8, 94, 20, 68, 409, 206, 410, 1, 33, 77, 411, 5, 14, 4, 213, 101, 30, 118, 27, 67, 145, 26, 15, 30, 146, 147, 412, 413, 182, 24, 214, 5, 414, 53, 8, 68, 415, 67, 145, 4, 101, 30, 146, 14, 416, 67, 417, 2, 418, 40, 2, 215, 419, 9, 420, 421, 216, 422, 30, 17, 423, 29, 15, 217, 55, 424, 425, 40, 2, 426, 3, 427, 9, 428, 429, 430, 56, 431, 2, 432, 433, 1, 148, 434, 435, 39, 218, 102, 2, 78, 219, 121, 5, 220, 149, 103, 20, 70, 0, 0, 100, 436, 2, 437, 438, 15, 439, 3, 440, 32, 441, 442, 40, 192, 443, 27, 3, 444, 221, 1, 445, 446, 5, 40, 221, 222, 0, 447, 1, 0, 74, 44, 448, 2, 449, 2, 450, 0, 150, 1, 0, 451, 102, 1, 0, 104, 0, 223, 1, 7, 79, 224, 225, 226, 22, 227, 151, 5, 14, 452, 228, 1, 80, 11, 453, 229, 3, 12, 216, 1, 454, 137, 455, 9, 0, 223, 222, 42, 102, 111, 77, 230, 9, 0, 189, 231, 456, 14, 457, 36, 126, 232, 25, 0, 458, 459, 32, 31, 460, 77, 461, 36, 57, 0, 201, 39, 462, 463, 56, 26, 130, 464, 152, 465, 0, 91, 1, 0, 133, 466, 467, 2, 22, 151, 25, 37, 6, 228, 1, 80, 11, 3, 0, 80, 468, 0, 21, 5, 75, 0, 69, 5, 469, 470, 233, 234, 210, 17, 471, 472, 473, 474, 475, 3, 12, 476, 477, 478, 479, 235, 480, 481, 7, 58, 59, 81, 35, 18, 236, 0, 482, 153, 30, 45, 78, 52, 74, 483, 484, 485, 39, 105, 19, 6, 486, 3, 100, 229, 72, 4, 154, 2, 487, 3, 0, 153, 488, 152, 88, 489, 490, 9, 18, 8, 26, 15, 2, 89, 22, 42, 12, 491, 3, 7, 58, 60, 81, 3, 0, 492, 1, 0, 95, 71, 149, 103, 61, 26, 493, 494, 96, 237, 87, 103, 495, 41, 75, 0, 135, 11, 106, 238, 20, 43, 211, 31, 496, 6, 0, 21, 497, 15, 198, 2, 103, 6, 0, 239, 1, 498, 11, 141, 36, 31, 499, 52, 15, 152, 500, 501, 2, 0, 69, 502, 17, 240, 241, 6, 26, 503, 504, 25, 0, 505, 506, 36, 155, 507, 184, 3, 0, 95, 71, 0, 21, 73, 508, 15, 242, 156, 28, 16, 8, 243, 230, 9, 16, 509, 244, 92, 242, 156, 28, 61, 33, 8, 19, 3, 7, 10, 82, 59, 9, 0, 69, 15, 17, 245, 6, 4, 73, 510, 16, 8, 23, 31, 511, 9, 37, 512, 28, 6, 0, 239, 1, 80, 15, 246, 3, 33, 8, 19, 28, 513, 24, 0, 514, 515, 19, 8, 516, 3, 31, 147, 18, 157, 0, 517, 1, 218, 19, 518, 244, 35, 519, 43, 185, 158, 5, 75, 2, 200, 46, 19, 6, 77, 520, 521, 6, 522, 107, 23, 247, 3, 44, 129, 28, 248, 33, 18, 47, 523, 76, 86, 43, 524, 158, 5, 75, 220, 525, 2, 249, 3, 526, 24, 217, 1, 527, 2, 237, 28, 13, 528, 1, 100, 45, 18, 47, 529, 530, 250, 26, 531, 251, 35, 76, 2, 252, 253, 532, 0, 533, 1, 46, 62, 127, 62, 534, 45, 535, 0, 536, 1, 131, 91, 250, 3, 159, 31, 38, 254, 9, 52, 7, 38, 247, 32, 0, 62, 1, 215, 107, 253, 537, 538, 539, 3, 255, 540, 256, 26, 257, 101, 541, 38, 14, 181, 134, 5, 542, 543, 24, 121, 5, 0, 72, 1, 159, 28, 13, 27, 56, 258, 544, 95, 131, 132, 98, 2, 12, 160, 56, 259, 3, 0, 71, 1, 7, 10, 82, 10, 3, 545, 28, 13, 137, 1, 19, 8, 546, 16, 17, 547, 3, 4, 260, 1, 548, 117, 12, 549, 2, 53, 22, 209, 138, 1, 37, 1, 12, 27, 23, 155, 550, 551, 261, 552, 262, 108, 13, 161, 3, 12, 0, 553, 2, 44, 90, 108, 162, 9, 55, 243, 263, 97, 140, 70, 0, 264, 1, 74, 19, 6, 4, 163, 554, 158, 3, 265, 2, 0, 555, 264, 1, 30, 56, 556, 557, 39, 558, 3, 0, 559, 560, 1, 30, 9, 0, 76, 22, 44, 561, 18, 562, 161, 2, 4, 563, 1, 564, 3, 45, 76, 38, 565, 3, 566, 1, 567, 84, 568, 16, 17, 3, 46, 73, 257, 5, 174, 89, 23, 266, 19, 569, 570, 67, 93, 146, 571, 572, 145, 5, 573, 5, 574, 0, 116, 5, 266, 575, 19, 2, 33, 164, 43, 3, 267, 268, 9, 8, 267, 90, 89, 576, 6, 164, 577, 578, 6, 579, 164, 235, 0, 580, 1, 0, 116, 108, 186, 47, 269, 26, 15, 18, 263, 84, 0, 207, 581, 582, 12, 27, 56, 258, 29, 106, 583, 584, 20, 87, 138, 1, 12, 585, 22, 270, 153, 109, 11, 110, 63, 3, 7, 10, 51, 271, 272, 48, 78, 586, 3, 4, 587, 588, 589, 25, 590, 591, 47, 592, 593, 45, 594, 3, 4, 595, 273, 596, 597, 598, 165, 48, 599, 0, 600, 13, 601, 29, 4, 274, 1, 104, 150, 2, 4, 274, 1, 105, 19, 48, 602, 5, 603, 604, 15, 605, 45, 606, 33, 18, 47, 0, 150, 1, 0, 104, 36, 607, 2, 80, 608, 3, 7, 10, 81, 81, 48, 609, 2, 61, 0, 610, 611, 45, 37, 43, 612, 5, 14, 0, 21, 15, 275, 276, 61, 110, 63, 613, 9, 48, 17, 0, 21, 231, 5, 614, 2, 615, 0, 616, 617, 240, 6, 11, 166, 618, 619, 7, 60, 59, 59, 7, 110, 63, 167, 620, 3, 11, 93, 621, 272, 48, 2, 149, 622, 277, 18, 623, 2, 61, 166, 32, 624, 7, 10, 10, 7, 5, 625, 7, 60, 59, 10, 16, 8, 626, 151, 5, 14, 0, 627, 109, 15, 275, 276, 628, 3, 0, 133, 629, 63, 13, 630, 1, 109, 11, 631, 0, 27, 1, 4, 278, 1, 632, 277, 13, 27, 29, 144, 633, 48, 13, 27, 29, 634, 6, 0, 635, 1, 636, 4, 637, 278, 1, 148, 246, 1, 279, 28, 13, 168, 11, 262, 108, 13, 161, 2, 638, 639, 13, 102, 1, 219, 640, 63, 641, 248, 0, 104, 13, 163, 5, 90, 0, 280, 1, 12, 39, 169, 148, 6, 105, 19, 2, 281, 3, 4, 168, 251, 23, 642, 31, 19, 18, 162, 9, 3, 4, 213, 101, 168, 193, 136, 0, 74, 0, 643, 1, 282, 38, 644, 645, 2, 254, 9, 42, 107, 646, 0, 647, 279, 1, 46, 62, 233, 7, 60, 224, 225, 648, 649, 650, 651, 652, 653, 654, 2, 655, 656, 0, 21, 64, 283, 49, 7, 10, 7, 82, 7, 10, 58, 79, 3, 226, 657, 658, 659, 0, 660, 1, 7, 10, 82, 10, 661, 273, 238, 3, 7, 10, 79, 82, 0, 64, 662, 13, 143, 227, 47, 0, 21, 64, 663, 37, 270, 664, 284, 285, 70, 11, 286, 5, 44, 665, 666, 5, 259, 107, 98, 0, 64, 167, 667, 32, 0, 668, 669, 83, 17, 4, 670, 671, 3, 0, 64, 18, 17, 672, 5, 126, 673, 265, 674, 1, 0, 143, 0, 21, 675, 5, 83, 676, 32, 0, 677, 195, 157, 57, 2, 287, 678, 679, 283, 49, 2, 12, 160, 680, 3, 7, 10, 79, 10, 0, 21, 64, 167, 681, 197, 51, 288, 24, 83, 2, 49, 6, 46, 682, 683, 0, 684, 685, 170, 0, 288, 17, 117, 686, 0, 20, 687, 49, 688, 3, 40, 13, 689, 690, 691, 692, 94, 693, 136, 694, 3, 0, 96, 289, 695, 36, 9, 91, 83, 2, 12, 160, 696, 29, 289, 697, 49, 698, 83, 13, 27, 6, 99, 2, 699, 9, 700, 4, 701, 702, 703, 5, 268, 44, 704, 38, 705, 134, 6, 706, 6, 0, 707, 132, 77, 78, 708, 94, 3, 7, 10, 58, 51, 0, 165, 709, 24, 4, 710, 711, 170, 0, 51, 252, 36, 0, 712, 713, 31, 8, 171, 714, 6, 0, 715, 1, 0, 165, 170, 20, 2, 716, 32, 31, 232, 0, 97, 717, 2, 154, 285, 1, 718, 78, 719, 720, 70, 721, 722, 15, 57, 290, 40, 28, 2, 49, 723, 157, 57, 724, 16, 24, 287, 118, 3, 0, 7, 10, 58, 59, 13, 106, 20, 725, 726, 32, 49, 13, 142, 727, 47, 728, 2, 729, 172, 730, 291, 281, 0, 72, 1, 159, 128, 14, 731, 732, 2, 9, 249, 14, 733, 25, 124, 41, 62, 26, 130, 15, 172, 17, 156, 734, 735, 0, 21, 736, 5, 203, 269, 6, 154, 737, 28, 18, 162, 9, 16, 8, 41, 0, 280, 1, 12, 39, 169, 62, 9, 0, 738, 88, 4, 163, 5, 141, 5, 0, 739, 1, 12, 39, 169, 740, 741, 742, 14, 46, 292, 18, 743, 12, 27, 3, 12, 744, 61, 745, 746, 747, 7, 10, 271, 10, 7, 10, 79, 7, 290, 40, 171, 748, 6, 0, 55, 749, 750, 751, 12, 142, 27, 3, 0, 752, 1, 753, 2, 754, 755, 2, 256, 18, 756, 255, 757, 8, 155, 758, 234, 282, 759, 3, 292, 3, 144, 212, 4, 760, 1, 761, 7, 10, 60, 58, 762, 15, 291, 763, 764, 765, 2, 766, 767, 106, 3, 0, 768, 769, 98, 261, 770, 771, 15, 57, 6, 46, 772, 773, 774, 13, 7, 60, 81, 51, 775, 776, 17, 245, 25, 0, 777, 778, 6, 44, 779, 23, 4, 780, 284, 30, 37, 20, 781, 782, 57, 24, 11, 783, 109, 20, 784, 9, 785, 1, 105, 19, 17, 41, 786, 24, 166, 23, 190, 110, 63, 202, 787, 214, 23, 40, 2, 788, 12, 147, 236, 172, 11, 6, 789, 11, 790, 1, 0, 791, 792, 55, 17, 26, 793, 139, 1, 794, 20, 43, 171, 205, 795, 6, 796, 2, 204, 286, 241, 5, 4, 260, 1, 797, 798]\n"
     ]
    }
   ],
   "source": [
    "text=\"\"\n",
    "#reading at most 100 lines\n",
    "with open('data.txt') as f:\n",
    "    i=0\n",
    "    for line in f.readlines():\n",
    "        text+=line    \n",
    "        i+=1\n",
    "        if i>=100:\n",
    "            break\n",
    "print(text)\n",
    "    \n",
    "words=text_to_word_sequence(text)\n",
    "\n",
    "vocab_to_int, int_to_vocab = create_lookup_tables(words)\n",
    "int_words = [vocab_to_int[word] for word in words]\n",
    "print(int_words)\n",
    "train_words=subsampling(int_words)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#---------------- SKIP GRAM ------------------\n",
    "def get_contextes(batch,i,window_size):\n",
    "    n=window_size//2\n",
    "    return list(set(batch[max(0,i-n):i]+batch[i+1:min(len(batch),i+n+1)]))\n",
    "\n",
    "#generator for batches\n",
    "def get_batch_sg(words,batch_size,window_size):\n",
    "    n_batches=len(words)//batch_size\n",
    "    words=words[:n_batches*batch_size]\n",
    "    for batch_start in range(0,len(words),batch_size):\n",
    "        batch=words[batch_start:batch_start+batch_size]\n",
    "        for i in range(len(batch)):\n",
    "            x,y=[],[]\n",
    "            center=batch[i]\n",
    "            y.extend(get_contextes(batch,i,window_size))\n",
    "            x.extend([center]*len(y))\n",
    "        yield x,y "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_sg(words,vocab_to_int):\n",
    "    vocab_size=len(vocab_to_int)\n",
    "    # hyperparameters\n",
    "    epochs=100\n",
    "    batch_size=100\n",
    "    window_size=5\n",
    "    word_dimension=300\n",
    "    n_samples=10\n",
    "    \n",
    "    inputs=tf.placeholder(tf.int32,[None],name='inputs') # size is variable , inputs are indexes of words in the batch\n",
    "    labels=tf.placeholder(tf.int32,[None,None],name='labels')\n",
    "    with tf.variable_scope(\"skip_gram\"):\n",
    "        embedding_V=tf.Variable(tf.random_uniform((vocab_size,word_dimension),-1,1))\n",
    "        embed=tf.nn.embedding_lookup(embedding_V,inputs) # chooses the given rows\n",
    "        embedding_U=tf.Variable(tf.random_normal((vocab_size,word_dimension)))\n",
    "        softmax_biases=tf.Variable(tf.zeros(vocab_size))\n",
    "        #loss with negative_sampling\n",
    "        loss=tf.nn.sampled_softmax_loss(weights=embedding_U,biases=softmax_biases,inputs=embed,labels=labels,num_sampled=n_samples,num_classes=vocab_size)\n",
    "        cost=tf.reduce_mean(loss)\n",
    "        optimizer=tf.train.AdamOptimizer().minimize(cost)\n",
    "    \n",
    "    \n",
    "    with tf.Session() as sess:\n",
    "        sess.run(tf.global_variables_initializer())\n",
    "        \n",
    "        for epoch in range(epochs):\n",
    "            cost_value=0\n",
    "            batch_generator=get_batch_sg(int_words,batch_size,window_size)\n",
    "            for x,y in batch_generator:\n",
    "                feed_dict={inputs:x,labels:np.array(y)[:,None]}  #labels:np.array(y)[:,None] adds a dimmension, is like squeeze(1)\n",
    "                _,cost_value=sess.run([optimizer,cost],feed_dict)\n",
    "                cost_value+=cost_value\n",
    "            print('epoch_{}'.format(epoch),'cost_value: ',cost_value)\n",
    "    return embedding_V,embedding_U\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch_0 cost_value:  62.023907\n",
      "epoch_1 cost_value:  47.717552\n",
      "epoch_2 cost_value:  54.585716\n",
      "epoch_3 cost_value:  46.912094\n",
      "epoch_4 cost_value:  29.777925\n",
      "epoch_5 cost_value:  26.018322\n",
      "epoch_6 cost_value:  20.571072\n",
      "epoch_7 cost_value:  36.816338\n",
      "epoch_8 cost_value:  24.565477\n",
      "epoch_9 cost_value:  22.84002\n",
      "epoch_10 cost_value:  24.794106\n",
      "epoch_11 cost_value:  6.6287956\n",
      "epoch_12 cost_value:  7.7672706\n",
      "epoch_13 cost_value:  5.041242\n",
      "epoch_14 cost_value:  19.385658\n",
      "epoch_15 cost_value:  5.813324\n",
      "epoch_16 cost_value:  2.8184562\n",
      "epoch_17 cost_value:  23.947823\n",
      "epoch_18 cost_value:  15.932253\n",
      "epoch_19 cost_value:  13.054022\n",
      "epoch_20 cost_value:  0.43791658\n",
      "epoch_21 cost_value:  0.015754502\n",
      "epoch_22 cost_value:  0.010242688\n",
      "epoch_23 cost_value:  4.792638\n",
      "epoch_24 cost_value:  4.587945\n",
      "epoch_25 cost_value:  0.0007517163\n",
      "epoch_26 cost_value:  0.00091312587\n",
      "epoch_27 cost_value:  0.023369104\n",
      "epoch_28 cost_value:  3.9572878\n",
      "epoch_29 cost_value:  0.00020478327\n",
      "epoch_30 cost_value:  0.00026377995\n",
      "epoch_31 cost_value:  9.512564\n",
      "epoch_32 cost_value:  2.578896\n",
      "epoch_33 cost_value:  2.741811e-06\n",
      "epoch_34 cost_value:  0.00011789263\n",
      "epoch_35 cost_value:  9.1790835e-06\n",
      "epoch_36 cost_value:  9.448348\n",
      "epoch_37 cost_value:  0.0014851871\n",
      "epoch_38 cost_value:  0.0005351356\n",
      "epoch_39 cost_value:  5.960463e-07\n",
      "epoch_40 cost_value:  1.8477305e-05\n",
      "epoch_41 cost_value:  9.21454e-05\n",
      "epoch_42 cost_value:  6.782825e-05\n",
      "epoch_43 cost_value:  9.53674e-07\n",
      "epoch_44 cost_value:  4.649154e-06\n",
      "epoch_45 cost_value:  1.4305106e-06\n",
      "epoch_46 cost_value:  0.0060457843\n",
      "epoch_47 cost_value:  0.004380932\n",
      "epoch_48 cost_value:  0.0045481957\n",
      "epoch_49 cost_value:  0.92277217\n",
      "epoch_50 cost_value:  0.0007732313\n",
      "epoch_51 cost_value:  0.0009388447\n",
      "epoch_52 cost_value:  0.00057901023\n",
      "epoch_53 cost_value:  7.033332e-06\n",
      "epoch_54 cost_value:  0.0059621935\n",
      "epoch_55 cost_value:  1.6689291e-06\n",
      "epoch_56 cost_value:  0.013271814\n",
      "epoch_57 cost_value:  1.7881382e-06\n",
      "epoch_58 cost_value:  0.0003789202\n",
      "epoch_59 cost_value:  2.2649747e-06\n",
      "epoch_60 cost_value:  0.025296502\n",
      "epoch_61 cost_value:  0.00020979432\n",
      "epoch_62 cost_value:  1.5391318\n",
      "epoch_63 cost_value:  2.205358e-05\n",
      "epoch_64 cost_value:  0.0045992956\n",
      "epoch_65 cost_value:  4.768371e-07\n",
      "epoch_66 cost_value:  0.03246197\n",
      "epoch_67 cost_value:  1.1920928e-07\n",
      "epoch_68 cost_value:  0.00039489748\n",
      "epoch_69 cost_value:  0.028137937\n",
      "epoch_70 cost_value:  0.0\n",
      "epoch_71 cost_value:  0.00031718836\n",
      "epoch_72 cost_value:  9.5245734e-05\n",
      "epoch_73 cost_value:  0.00020002223\n",
      "epoch_74 cost_value:  0.00016390542\n",
      "epoch_75 cost_value:  1.1920928e-07\n",
      "epoch_76 cost_value:  0.0004672407\n",
      "epoch_77 cost_value:  6.461029e-05\n",
      "epoch_78 cost_value:  1.1920928e-07\n",
      "epoch_79 cost_value:  0.00017618283\n",
      "epoch_80 cost_value:  0.16926017\n",
      "epoch_81 cost_value:  6.3266845\n",
      "epoch_82 cost_value:  0.0\n",
      "epoch_83 cost_value:  0.0\n",
      "epoch_84 cost_value:  0.0033060953\n",
      "epoch_85 cost_value:  1.0728834e-06\n",
      "epoch_86 cost_value:  0.0\n",
      "epoch_87 cost_value:  0.0\n",
      "epoch_88 cost_value:  0.0\n",
      "epoch_89 cost_value:  0.0\n",
      "epoch_90 cost_value:  0.0\n",
      "epoch_91 cost_value:  0.0\n",
      "epoch_92 cost_value:  0.0020294683\n",
      "epoch_93 cost_value:  4.6491564e-06\n",
      "epoch_94 cost_value:  9.703375e-05\n",
      "epoch_95 cost_value:  6.0199687e-05\n",
      "epoch_96 cost_value:  1.1324847e-05\n",
      "epoch_97 cost_value:  3.4808774e-05\n",
      "epoch_98 cost_value:  1.1563264e-05\n",
      "epoch_99 cost_value:  0.0\n"
     ]
    }
   ],
   "source": [
    "embedding_V,embedding_U=train_sg(words,vocab_to_int)\n",
    "word_embeddings=embedding_V+embedding_U"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------------------ CBOW -------------------\n",
    "\n",
    "def get_batch_cbow(int_words,batch_size,window_size):\n",
    "    n_batches=len(int_words)//batch_size\n",
    "    int_words=int_words[:n_batches*batch_size]\n",
    "    center_ind=window_size//2\n",
    "    \n",
    "    for bath_start in range(0,len(int_words),batch_size):\n",
    "        batch=int_words[bath_start:bath_start+batch_size]\n",
    "        surroundings=np.ndarray((batch_size-(2*center_ind),window_size-1),np.int32)\n",
    "        labels=np.ndarray((batch_size-(2*center_ind),1),np.int32)\n",
    "        for i in range(center_ind,batch_size-center_ind,1):    \n",
    "            center=batch[i]\n",
    "            col_idx=0\n",
    "            for j in range(window_size):\n",
    "                if j==window_size//2:\n",
    "                    continue\n",
    "                else:\n",
    "                    surroundings[i-center_ind,col_idx]=batch[i-center_ind+j]\n",
    "                    col_idx+=1\n",
    "            labels[i-center_ind,0]=center\n",
    "            \n",
    "        yield surroundings,labels\n",
    "        \n",
    "\n",
    "def train_cbow(int_words,vocab_to_int):\n",
    "    \n",
    "    # hyperparameters\n",
    "    epochs=200\n",
    "    batch_size=100\n",
    "    window_size=5\n",
    "    dimension=300\n",
    "    n_samples=20\n",
    "    \n",
    "    half_window=window_size//2\n",
    "    vocab_size=len(vocab_to_int)\n",
    "    \n",
    "    inputs=tf.placeholder(tf.int32,[batch_size-(2*half_window),window_size-1])\n",
    "    labels=tf.placeholder(tf.int32,[batch_size-(2*half_window),1])\n",
    "    with tf.variable_scope('cbow'):\n",
    "    \n",
    "        embeddings=tf.Variable(tf.random_uniform((vocab_size,dimension),-1,1))\n",
    "\n",
    "        #get_avg_embed\n",
    "        embeds=None\n",
    "        for i in range(window_size-1):\n",
    "            embedding_i=tf.nn.embedding_lookup(embeddings,inputs[:,i])\n",
    "            emb_x,emb_y = embedding_i.get_shape().as_list()\n",
    "            if embeds is None:\n",
    "                embeds=tf.reshape(embedding_i,[emb_x,emb_y,1])\n",
    "            else:\n",
    "                embeds=tf.concat([embeds,tf.reshape(embedding_i,[emb_x,emb_y,1])],2)\n",
    "        avg_embed=tf.reduce_mean(embeds,2,keepdims=False)\n",
    "\n",
    "        softmax_w=tf.Variable(tf.random_normal((vocab_size,dimension)))\n",
    "        softmax_b=tf.Variable(tf.zeros(vocab_size))\n",
    "\n",
    "        loss=tf.nn.sampled_softmax_loss(weights=softmax_w,biases=softmax_b,inputs=avg_embed,labels=labels,num_sampled=n_samples,num_classes=vocab_size)\n",
    "        cost=tf.reduce_mean(loss)\n",
    "        optimizer=tf.train.AdamOptimizer().minimize(cost)\n",
    "\n",
    "    with tf.Session() as sess:\n",
    "        sess.run(tf.global_variables_initializer())\n",
    "        \n",
    "        for epoch in range(epochs):\n",
    "            batch_generator=get_batch_cbow(int_words,batch_size,window_size)\n",
    "            cost_value=0\n",
    "            \n",
    "            for x,y in batch_generator:\n",
    "                feed_dic={inputs:x, labels:y}\n",
    "                _,cost_value=sess.run([optimizer,cost],feed_dict=feed_dic)\n",
    "                cost_value+=cost_value\n",
    "            print('epoch_{}'.format(epoch),'cost_value: ',cost_value)\n",
    "            \n",
    "    return embeddings,softmax_w\n",
    "        \n",
    "       \n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch_0 cost_value:  18.463247\n",
      "epoch_1 cost_value:  16.95909\n",
      "epoch_2 cost_value:  18.090807\n",
      "epoch_3 cost_value:  15.196023\n",
      "epoch_4 cost_value:  13.884656\n",
      "epoch_5 cost_value:  12.252251\n",
      "epoch_6 cost_value:  13.827466\n",
      "epoch_7 cost_value:  11.537938\n",
      "epoch_8 cost_value:  12.163001\n",
      "epoch_9 cost_value:  10.341201\n",
      "epoch_10 cost_value:  9.090264\n",
      "epoch_11 cost_value:  8.916907\n",
      "epoch_12 cost_value:  8.668685\n",
      "epoch_13 cost_value:  8.29587\n",
      "epoch_14 cost_value:  7.705408\n",
      "epoch_15 cost_value:  7.193191\n",
      "epoch_16 cost_value:  6.596796\n",
      "epoch_17 cost_value:  5.3499675\n",
      "epoch_18 cost_value:  4.808045\n",
      "epoch_19 cost_value:  5.202244\n",
      "epoch_20 cost_value:  4.412601\n",
      "epoch_21 cost_value:  3.3996048\n",
      "epoch_22 cost_value:  4.1421094\n",
      "epoch_23 cost_value:  3.3975832\n",
      "epoch_24 cost_value:  3.9550858\n",
      "epoch_25 cost_value:  3.1409779\n",
      "epoch_26 cost_value:  2.7786732\n",
      "epoch_27 cost_value:  3.2275574\n",
      "epoch_28 cost_value:  2.8136652\n",
      "epoch_29 cost_value:  2.25799\n",
      "epoch_30 cost_value:  1.7740451\n",
      "epoch_31 cost_value:  1.6948042\n",
      "epoch_32 cost_value:  1.5170794\n",
      "epoch_33 cost_value:  1.8615522\n",
      "epoch_34 cost_value:  2.0968876\n",
      "epoch_35 cost_value:  1.1615479\n",
      "epoch_36 cost_value:  0.8305667\n",
      "epoch_37 cost_value:  1.2217426\n",
      "epoch_38 cost_value:  1.2952319\n",
      "epoch_39 cost_value:  0.7585762\n",
      "epoch_40 cost_value:  0.80164075\n",
      "epoch_41 cost_value:  1.0416341\n",
      "epoch_42 cost_value:  0.6445909\n",
      "epoch_43 cost_value:  0.8649357\n",
      "epoch_44 cost_value:  0.4915744\n",
      "epoch_45 cost_value:  0.66224414\n",
      "epoch_46 cost_value:  0.6095031\n",
      "epoch_47 cost_value:  0.49401078\n",
      "epoch_48 cost_value:  0.48660293\n",
      "epoch_49 cost_value:  0.482903\n",
      "epoch_50 cost_value:  0.25878218\n",
      "epoch_51 cost_value:  0.24842572\n",
      "epoch_52 cost_value:  0.43422237\n",
      "epoch_53 cost_value:  0.89530706\n",
      "epoch_54 cost_value:  0.5405988\n",
      "epoch_55 cost_value:  0.54179424\n",
      "epoch_56 cost_value:  0.24662115\n",
      "epoch_57 cost_value:  0.39170274\n",
      "epoch_58 cost_value:  0.53054184\n",
      "epoch_59 cost_value:  0.22945876\n",
      "epoch_60 cost_value:  0.23374309\n",
      "epoch_61 cost_value:  0.40045783\n",
      "epoch_62 cost_value:  0.14065136\n",
      "epoch_63 cost_value:  0.27135292\n",
      "epoch_64 cost_value:  0.3636637\n",
      "epoch_65 cost_value:  0.093754895\n",
      "epoch_66 cost_value:  0.41004482\n",
      "epoch_67 cost_value:  0.19140458\n",
      "epoch_68 cost_value:  0.36074758\n",
      "epoch_69 cost_value:  0.15471281\n",
      "epoch_70 cost_value:  0.055980753\n",
      "epoch_71 cost_value:  0.0566054\n",
      "epoch_72 cost_value:  0.15210238\n",
      "epoch_73 cost_value:  0.28981596\n",
      "epoch_74 cost_value:  0.3404733\n",
      "epoch_75 cost_value:  0.3228172\n",
      "epoch_76 cost_value:  0.10872325\n",
      "epoch_77 cost_value:  0.12647115\n",
      "epoch_78 cost_value:  0.07795902\n",
      "epoch_79 cost_value:  0.31756788\n",
      "epoch_80 cost_value:  0.074509986\n",
      "epoch_81 cost_value:  0.11527723\n",
      "epoch_82 cost_value:  0.123429626\n",
      "epoch_83 cost_value:  0.15124011\n",
      "epoch_84 cost_value:  0.06698227\n",
      "epoch_85 cost_value:  0.118953295\n",
      "epoch_86 cost_value:  0.123519875\n",
      "epoch_87 cost_value:  0.09249896\n",
      "epoch_88 cost_value:  0.0729903\n",
      "epoch_89 cost_value:  0.3061838\n",
      "epoch_90 cost_value:  0.16797422\n",
      "epoch_91 cost_value:  0.07322013\n",
      "epoch_92 cost_value:  0.049017966\n",
      "epoch_93 cost_value:  0.13005368\n",
      "epoch_94 cost_value:  0.16991444\n",
      "epoch_95 cost_value:  0.1113142\n",
      "epoch_96 cost_value:  0.036382306\n",
      "epoch_97 cost_value:  0.08988138\n",
      "epoch_98 cost_value:  0.10812304\n",
      "epoch_99 cost_value:  0.08305928\n",
      "epoch_100 cost_value:  0.06339104\n",
      "epoch_101 cost_value:  0.16230777\n",
      "epoch_102 cost_value:  0.13212727\n",
      "epoch_103 cost_value:  0.1033893\n",
      "epoch_104 cost_value:  0.09606532\n",
      "epoch_105 cost_value:  0.025547631\n",
      "epoch_106 cost_value:  0.04781552\n",
      "epoch_107 cost_value:  0.021214679\n",
      "epoch_108 cost_value:  0.04008502\n",
      "epoch_109 cost_value:  0.06687663\n",
      "epoch_110 cost_value:  0.15690021\n",
      "epoch_111 cost_value:  0.11998985\n",
      "epoch_112 cost_value:  0.110473596\n",
      "epoch_113 cost_value:  0.055300612\n",
      "epoch_114 cost_value:  0.100044765\n",
      "epoch_115 cost_value:  0.050229404\n",
      "epoch_116 cost_value:  0.038276795\n",
      "epoch_117 cost_value:  0.05177922\n",
      "epoch_118 cost_value:  0.07370148\n",
      "epoch_119 cost_value:  0.0822871\n",
      "epoch_120 cost_value:  0.037173856\n",
      "epoch_121 cost_value:  0.049852014\n",
      "epoch_122 cost_value:  0.043724004\n",
      "epoch_123 cost_value:  0.06434954\n",
      "epoch_124 cost_value:  0.06805367\n",
      "epoch_125 cost_value:  0.05283181\n",
      "epoch_126 cost_value:  0.044624317\n",
      "epoch_127 cost_value:  0.05409052\n",
      "epoch_128 cost_value:  0.04847228\n",
      "epoch_129 cost_value:  0.06905496\n",
      "epoch_130 cost_value:  0.040924925\n",
      "epoch_131 cost_value:  0.023162544\n",
      "epoch_132 cost_value:  0.020886311\n",
      "epoch_133 cost_value:  0.017828176\n",
      "epoch_134 cost_value:  0.04118114\n",
      "epoch_135 cost_value:  0.026657969\n",
      "epoch_136 cost_value:  0.027644297\n",
      "epoch_137 cost_value:  0.2419635\n",
      "epoch_138 cost_value:  0.027084246\n",
      "epoch_139 cost_value:  0.07623958\n",
      "epoch_140 cost_value:  0.04206072\n",
      "epoch_141 cost_value:  0.056004006\n",
      "epoch_142 cost_value:  0.022448465\n",
      "epoch_143 cost_value:  0.020481892\n",
      "epoch_144 cost_value:  0.1516837\n",
      "epoch_145 cost_value:  0.0389936\n",
      "epoch_146 cost_value:  0.030122047\n",
      "epoch_147 cost_value:  0.023572942\n",
      "epoch_148 cost_value:  0.03242123\n",
      "epoch_149 cost_value:  0.026315568\n",
      "epoch_150 cost_value:  0.062376548\n",
      "epoch_151 cost_value:  0.023221105\n",
      "epoch_152 cost_value:  0.036741946\n",
      "epoch_153 cost_value:  0.045204777\n",
      "epoch_154 cost_value:  0.11812524\n",
      "epoch_155 cost_value:  0.066291936\n",
      "epoch_156 cost_value:  0.09613905\n",
      "epoch_157 cost_value:  0.015831092\n",
      "epoch_158 cost_value:  0.024638565\n",
      "epoch_159 cost_value:  0.164929\n",
      "epoch_160 cost_value:  0.013966565\n",
      "epoch_161 cost_value:  0.057685386\n",
      "epoch_162 cost_value:  0.041208077\n",
      "epoch_163 cost_value:  0.027049655\n",
      "epoch_164 cost_value:  0.017237408\n",
      "epoch_165 cost_value:  0.02548164\n",
      "epoch_166 cost_value:  0.04837744\n",
      "epoch_167 cost_value:  0.045646325\n",
      "epoch_168 cost_value:  0.019040504\n",
      "epoch_169 cost_value:  0.018641572\n",
      "epoch_170 cost_value:  0.018567717\n",
      "epoch_171 cost_value:  0.072868995\n",
      "epoch_172 cost_value:  0.014318518\n",
      "epoch_173 cost_value:  0.026554974\n",
      "epoch_174 cost_value:  0.028473316\n",
      "epoch_175 cost_value:  0.02831498\n",
      "epoch_176 cost_value:  0.012507851\n",
      "epoch_177 cost_value:  0.03165951\n",
      "epoch_178 cost_value:  0.017643293\n",
      "epoch_179 cost_value:  0.020862237\n",
      "epoch_180 cost_value:  0.00559073\n",
      "epoch_181 cost_value:  0.03233518\n",
      "epoch_182 cost_value:  0.009853407\n",
      "epoch_183 cost_value:  0.0072351694\n",
      "epoch_184 cost_value:  0.046306137\n",
      "epoch_185 cost_value:  0.0057201595\n",
      "epoch_186 cost_value:  0.00990944\n",
      "epoch_187 cost_value:  0.0062151346\n",
      "epoch_188 cost_value:  0.05506596\n",
      "epoch_189 cost_value:  0.041578546\n",
      "epoch_190 cost_value:  0.04552867\n",
      "epoch_191 cost_value:  0.007900521\n",
      "epoch_192 cost_value:  0.010636332\n",
      "epoch_193 cost_value:  0.020789849\n",
      "epoch_194 cost_value:  0.03820911\n",
      "epoch_195 cost_value:  0.011024331\n",
      "epoch_196 cost_value:  0.034914512\n",
      "epoch_197 cost_value:  0.0583671\n",
      "epoch_198 cost_value:  0.02487682\n",
      "epoch_199 cost_value:  0.0066976394\n"
     ]
    }
   ],
   "source": [
    "embedding_U,embedding_V=train_cbow(int_words,vocab_to_int)\n",
    "word_embeddings=embedding_U+embedding_V"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
